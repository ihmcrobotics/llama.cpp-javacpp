--- ggml/src/ggml-cuda/CMakeLists.txt	2025-02-19 14:18:15.243889743 -0600
+++ ggml/src/ggml-cuda/CMakeLists.txt	2025-02-19 14:45:22.209097858 -0600
@@ -1,42 +1,43 @@
-cmake_minimum_required(VERSION 3.18)  # for CMAKE_CUDA_ARCHITECTURES
+cmake_minimum_required(VERSION 3.16)
+project(ggml-cuda LANGUAGES C CUDA)

-find_package(CUDAToolkit)
+include(FindCUDA)
+find_package(CUDA REQUIRED)

-if (CUDAToolkit_FOUND)
+if (CUDA_FOUND)
     message(STATUS "CUDA Toolkit found")

-    if (NOT DEFINED CMAKE_CUDA_ARCHITECTURES)
-        # native == GPUs available at build time
-        # 52     == Maxwell, lowest CUDA 12 standard
-        # 60     == P100, FP16 CUDA intrinsics
-        # 61     == Pascal, __dp4a instruction (per-byte integer dot product)
-        # 70     == V100, FP16 tensor cores
-        # 75     == Turing, int8 tensor cores
-        if (GGML_NATIVE AND CUDAToolkit_VERSION VERSION_GREATER_EQUAL "11.6" AND CMAKE_VERSION VERSION_GREATER_EQUAL "3.24")
-            set(CMAKE_CUDA_ARCHITECTURES "native")
-        elseif(GGML_CUDA_F16 OR GGML_CUDA_DMMV_F16)
-            set(CMAKE_CUDA_ARCHITECTURES "60;61;70;75;80")
-        else()
-            set(CMAKE_CUDA_ARCHITECTURES "52;61;70;75;80")
-        endif()
+    if (GGML_CUDA_F16 OR GGML_CUDA_DMMV_F16)
+        set(CUDA_ARCH_LIST "60 61 70 75 80")
+    else()
+        set(CUDA_ARCH_LIST "52 61 70 75 80")
     endif()
-    message(STATUS "Using CUDA architectures: ${CMAKE_CUDA_ARCHITECTURES}")
+
+    set(GENCODE_FLAGS "")
+    foreach(arch ${CUDA_ARCH_LIST})
+        list(APPEND GENCODE_FLAGS
+            "-gencode arch=compute_${arch},code=sm_${arch}"
+            "-gencode arch=compute_${arch},code=compute_${arch}"
+        )
+    endforeach()
+    list(APPEND CUDA_NVCC_FLAGS ${GENCODE_FLAGS})
+    message(STATUS "Using CUDA architectures: ${CUDA_ARCH_LIST}")

     enable_language(CUDA)

-    file(GLOB   GGML_HEADERS_CUDA "*.cuh")
+    file(GLOB GGML_HEADERS_CUDA "*.cuh")
     list(APPEND GGML_HEADERS_CUDA "../../include/ggml-cuda.h")

-    file(GLOB   GGML_SOURCES_CUDA "*.cu")
-    file(GLOB   SRCS "template-instances/fattn-mma*.cu")
+    file(GLOB GGML_SOURCES_CUDA "*.cu")
+    file(GLOB SRCS "template-instances/fattn-mma*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})
-    file(GLOB   SRCS "template-instances/mmq*.cu")
+    file(GLOB SRCS "template-instances/mmq*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})

     if (GGML_CUDA_FA_ALL_QUANTS)
-        file(GLOB   SRCS "template-instances/fattn-vec*.cu")
+        file(GLOB SRCS "template-instances/fattn-vec*.cu")
         list(APPEND GGML_SOURCES_CUDA ${SRCS})
-        add_compile_definitions(GGML_CUDA_FA_ALL_QUANTS)
+        add_definitions(-DGGML_CUDA_FA_ALL_QUANTS)
     else()
         file(GLOB   SRCS "template-instances/fattn-vec*q4_0-q4_0.cu")
         list(APPEND GGML_SOURCES_CUDA ${SRCS})
@@ -46,52 +47,63 @@
         list(APPEND GGML_SOURCES_CUDA ${SRCS})
     endif()

-    ggml_add_backend_library(ggml-cuda
-                             ${GGML_HEADERS_CUDA}
-                             ${GGML_SOURCES_CUDA}
-                            )
+    add_library(ggml-cuda ${GGML_HEADERS_CUDA} ${GGML_SOURCES_CUDA})

-    add_compile_definitions(GGML_CUDA_PEER_MAX_BATCH_SIZE=${GGML_CUDA_PEER_MAX_BATCH_SIZE})
+    add_definitions(GGML_CUDA_PEER_MAX_BATCH_SIZE=${GGML_CUDA_PEER_MAX_BATCH_SIZE})

     if (GGML_CUDA_GRAPHS)
-        add_compile_definitions(GGML_CUDA_USE_GRAPHS)
+        add_definitions(-DGGML_CUDA_USE_GRAPHS)
     endif()

     if (GGML_CUDA_FORCE_MMQ)
-        add_compile_definitions(GGML_CUDA_FORCE_MMQ)
+        add_definitions(GGML_CUDA_FORCE_MMQ)
     endif()

     if (GGML_CUDA_FORCE_CUBLAS)
-        add_compile_definitions(GGML_CUDA_FORCE_CUBLAS)
+        add_definitions(GGML_CUDA_FORCE_CUBLAS)
     endif()

     if (GGML_CUDA_NO_VMM)
-        add_compile_definitions(GGML_CUDA_NO_VMM)
+        add_definitions(GGML_CUDA_NO_VMM)
     endif()

     if (GGML_CUDA_F16 OR GGML_CUDA_DMMV_F16)
-        add_compile_definitions(GGML_CUDA_F16)
+        add_definitions(GGML_CUDA_F16)
     endif()

     if (GGML_CUDA_NO_PEER_COPY)
-        add_compile_definitions(GGML_CUDA_NO_PEER_COPY)
+        add_definitions(GGML_CUDA_NO_PEER_COPY)
     endif()

     if (GGML_STATIC)
         if (WIN32)
-            # As of 12.3.1 CUDA Toolkit for Windows does not offer a static cublas library
-            target_link_libraries(ggml-cuda PRIVATE CUDA::cudart_static CUDA::cublas CUDA::cublasLt)
-        else ()
-            target_link_libraries(ggml-cuda PRIVATE  CUDA::cudart_static CUDA::cublas_static CUDA::cublasLt_static)
+            set(CUDA_CUDART_LIB "cudart_static")
+            set(CUDA_CUBLAS_LIB "cublas")
+            set(CUDA_CUBLASLT_LIB "cublasLt")
+        else()
+            set(CUDA_CUDART_LIB "cudart_static")
+            set(CUDA_CUBLAS_LIB "cublas_static")
+            set(CUDA_CUBLASLT_LIB "cublasLt_static")
         endif()
     else()
-        target_link_libraries(ggml-cuda PRIVATE CUDA::cudart CUDA::cublas CUDA::cublasLt)
-    endif()
-
-    if (GGML_CUDA_NO_VMM)
-        # No VMM requested, no need to link directly with the cuda driver lib (libcuda.so)
-    else()
-        target_link_libraries(ggml-cuda PRIVATE CUDA::cuda_driver)
+        set(CUDA_CUDART_LIB "cudart")
+        set(CUDA_CUBLAS_LIB "cublas")
+        set(CUDA_CUBLASLT_LIB "cublasLt")
+    endif()
+
+    find_library(CUDA_CUDART_PATH NAMES ${CUDA_CUDART_LIB} PATHS ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
+    find_library(CUDA_CUBLAS_PATH NAMES ${CUDA_CUBLAS_LIB} PATHS ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
+    find_library(CUDA_CUBLASLT_PATH NAMES ${CUDA_CUBLASLT_LIB} PATHS ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
+
+    target_link_libraries(ggml-cuda PRIVATE
+        ${CUDA_CUDART_PATH}
+        ${CUDA_CUBLAS_PATH}
+        ${CUDA_CUBLASLT_PATH}
+    )
+
+    if (NOT GGML_CUDA_NO_VMM)
+        find_library(CUDA_DRIVER_LIB "cuda" PATHS ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
+        target_link_libraries(ggml-cuda PRIVATE ${CUDA_DRIVER_LIB})
     endif()

     set(CUDA_CXX_FLAGS "")
@@ -137,8 +149,14 @@
     endif()

     if (NOT MSVC)
-        list(APPEND CUDA_CXX_FLAGS -Wno-pedantic)
+        list(APPEND CUDA_NVCC_FLAGS -Xcompiler -Wno-pedantic)
+    endif()
+    if (GGML_FATAL_WARNINGS)
+        list(APPEND CUDA_NVCC_FLAGS -Werror all-warnings)
     endif()
+    set_target_properties(ggml-cuda PROPERTIES
+        CUDA_NVCC_FLAGS "${CUDA_NVCC_FLAGS}"
+    )

     list(JOIN   CUDA_CXX_FLAGS " " CUDA_CXX_FLAGS_JOINED)  # pass host compiler flags as a single argument

